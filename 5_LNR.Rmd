```{r}
library("ggplot2") # plots
library("patchwork") # arranging plots
library("dplyr") # data wrangling
library("extraDistr") # truncated normal
library("tidyr") # wide to long and vice versa
library("stringr") # convert to capital letters with str_to_upper()
library("scales") # plot labels formatting
library("tidybayes") # geom_pointinterval
library("parallel") # multi core computing
library("rstan") # model fitting
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```



```{r 'pp-check-functions'}
pp_check_overall_lnr <- function(data, modelfit, npred){
  J <- data %>% group_by(subject) %>% count() %>% pull(n) %>% max()
  I <- length(unique(data$subject))
  filler <- -9999
  idx <- round(seq(from = 1, to = 4000, length.out = npred),0)
  y_pred <- rstan::extract(modelfit, "Y_pred")$Y_pred[idx,,,]
  
  pp_dat2 <- matrix(aperm(y_pred, c(3,2,1,4)), ncol = 3) %>% 
    as.data.frame() %>% 
    rename("rt" = V1, "accuracy" = V2, "cond" = V3) %>% 
    mutate(pp = rep(1:npred, each = I*J),
           s = rep(rep(1:I, each = J), times = npred)) %>% 
    filter(rt != filler, accuracy != filler, cond != filler)
  
  individual_q_rt2 <- pp_dat2 %>%
    group_by(pp, cond) %>%
    summarize(q.1 = quantile(rt , probs = .1),
              q.3 = quantile(rt , probs = .3),
              q.5 = quantile(rt , probs = .5),
              q.7 = quantile(rt , probs = .7),
              q.9 = quantile(rt , probs = .9)) %>%
    tidyr::pivot_longer(names_to = "q", values_to = "rt_pp", cols = q.1:q.9) %>%
    distinct(q,cond,rt_pp,pp)
  
  plot_dat_individual_pp2 <- pp_dat2 %>% 
    mutate(q = case_when(rt  <= quantile(rt , probs = .1) ~ "q.1",
                         rt <= quantile(rt , probs = .3) & rt > quantile(rt , probs = .1) ~ "q.3",
                         rt <= quantile(rt , probs = .5) & rt > quantile(rt , probs = .3) ~ "q.5",
                         rt <= quantile(rt , probs = .7) & rt > quantile(rt , probs = .5) ~ "q.7",
                         rt <= quantile(rt , probs = .9) & rt > quantile(rt , probs = .7)~ "q.9",
                         TRUE ~ "q.>9")) %>% 
    filter(q != "q.>9") %>% 
    group_by(q, pp,cond) %>% 
    summarize(p_corr_pp = mean(accuracy == 1)) %>% 
    left_join(individual_q_rt2) %>% 
    rename("p_corr" = p_corr_pp,
           "rt" = rt_pp) %>% 
    mutate(type = "predicted") %>% 
    select(q, cond, p_corr, rt, type, pp)
  
  plot_dat_pp_rt2 <- pp_dat2 %>% 
    group_by(cond) %>% 
    summarize(q.1 = quantile(rt , probs = .1),
              q.3 = quantile(rt , probs = .3),
              q.5 = quantile(rt , probs = .5),
              q.7 = quantile(rt , probs = .7),
              q.9 = quantile(rt , probs = .9)) %>% 
    tidyr::pivot_longer(names_to = "q", values_to = "rt", cols = q.1:q.9) %>% 
    distinct(cond,q,rt)
  
  plot_dat_pp2 <- pp_dat2 %>% 
    group_by(pp,cond) %>% 
    mutate(q = case_when(rt  <= quantile(rt , probs = .1) ~ "q.1",
                         rt <= quantile(rt , probs = .3) & rt > quantile(rt , probs = .1) ~ "q.3",
                         rt <= quantile(rt , probs = .5) & rt > quantile(rt , probs = .3) ~ "q.5",
                         rt <= quantile(rt , probs = .7) & rt > quantile(rt , probs = .5) ~ "q.7",
                         rt <= quantile(rt , probs = .9) & rt > quantile(rt , probs = .7)~ "q.9",
                         TRUE ~ "q.>9")) %>% 
    group_by(q,cond) %>% 
    summarize(p_corr = mean(accuracy == 1)) %>% 
    left_join(plot_dat_pp_rt2) %>% 
    filter(q != "q.>9")
  
  # # observed data
  q_rt2 <- data %>%
    mutate(accuracy = ifelse(accuracy == 1, 1, 2),
           cond = ifelse(congruency == "1", -0.5, 0.5)) %>% 
    group_by(cond) %>% 
    mutate(q.1 = quantile(rt, probs = .1),
           q.3 = quantile(rt, probs = .3),
           q.5 = quantile(rt, probs = .5),
           q.7 = quantile(rt, probs = .7),
           q.9 = quantile(rt, probs = .9)) %>%
    tidyr::pivot_longer(names_to = "q", values_to = "rt_agg", cols = q.1:q.9) %>%
    distinct(q,cond,rt_agg) %>% 
    rename("rt" = rt_agg)
  
  plot_dat_observed2 <- data %>% 
    mutate(accuracy = ifelse(accuracy == 1, 1, 2),
           cond = ifelse(congruency == "1", -0.5, 0.5)) %>% 
    mutate(q = case_when(rt <= quantile(rt, probs = .1) ~ "q.1",
                         rt <= quantile(rt, probs = .3) & rt > quantile(rt, probs = .1) ~ "q.3",
                         rt <= quantile(rt, probs = .5) & rt > quantile(rt, probs = .3) ~ "q.5",
                         rt <= quantile(rt, probs = .7) & rt > quantile(rt, probs = .5) ~ "q.7",
                         rt <= quantile(rt, probs = .9) & rt > quantile(rt, probs = .7)~ "q.9",
                         TRUE ~ "q.>9")) %>% 
    group_by(q,cond) %>% 
    summarize(p_corr = mean(accuracy == 1)) %>% 
    left_join(q_rt2) %>% 
    filter(q != "q.>9") %>% 
    mutate(type = "observed", pp = NA)
  
  colors <- c("Observed" = "#c51b8a", "Predicted" = "#3182bd")  
  
  pp_lnr <- ggplot2::ggplot(plot_dat_individual_pp2, aes(x = rt, y = p_corr)) +
    geom_point(alpha=0.2,  color = "#9ecae1") +
    geom_point(data = plot_dat_pp2, size = 3, aes(color = "Predicted")) +
    geom_line(data = plot_dat_pp2, size = 0.9, aes(color = "Predicted"))+
    geom_point(data = plot_dat_observed2, size = 3, aes(color = "Observed"))+
    geom_line(data = plot_dat_observed2, aes(color = "Observed"), linetype = "dashed")+
    labs(title = "RT and Proportion correct", subtitle = "Groups of points mark the 10th, 30th, 50th,\n70th, and 90th percentiles of the data", x = "RT in seconds", y = "Proportion Correct",color = "") +
    scale_color_manual(values = colors) +
    scale_y_continuous(limits = c(0.8,1))+
    theme_bw() +
    facet_wrap(~cond)
  
  return(pp_lnr)
}

plot_cdf_pp <- function(data, modelfit, npred = 500, subject = NULL, factors = NULL, stat = NULL, 
                       stat_name = "", adjust = 1, ci = c(0.025, 0.5, 0.975), do_plot = TRUE, 
                       xlim = NULL, ylim = NULL, layout = NULL, mfcol = TRUE, probs = c(1:99)/100, 
                       data_lwd = 1, fit_lwd = 2, qp_cex = 1, q_points = c(0.1,0.3, 0.5, 0.7, 0.9), 
                       pqp_cex = 0.5, lpos = "topleft", 
                       signalFactor = "S", zROC = FALSE, qfun = qnorm, lim = NULL, 
                       rocfit_cex = 0.5){
  
  J <- data %>% group_by(subject) %>% count() %>% pull(n) %>% max()
  I <- length(unique(data$subject))
  data <- data %>% 
  transmute(CT = as.factor(congruency),
            R = as.factor(ifelse(accuracy == 1, 1, 2)),
            rt = rt)
  filler <- -9999
  idx <- round(seq(from = 1, to = 4000, length.out = npred),0)
  y_pred <- rstan::extract(modelfit, "Y_pred")$Y_pred[idx,,,]
  
  pp_dat2 <- matrix(aperm(y_pred, c(3,2,1,4)), ncol = 3) %>% 
    as.data.frame() %>% 
    rename("rt" = V1, "accuracy" = V2, "cond" = V3) %>% 
    mutate(pp = rep(1:npred, each = I*J),
           s = rep(rep(1:I, each = J), times = npred)) %>% 
    filter(rt != filler, accuracy != filler, cond != filler)
 
# postn [1:nsamps] CT [0,1] R [1,2] rt [in sec]
  pp <- pp_dat2 %>% 
    transmute(postn = pp,
              CT = as.factor(ifelse(cond == -0.5, 1, 2)),
              R = as.factor(ifelse(accuracy == 1, 1, 2)),
              rt = rt)

  if (!is.null(subject)) {
    snams <- levels(data$subjects)
    if (is.numeric(subject)){ 
      subject <- snams[subject]
      dat <- droplevels(data[data$subjects %in% subject, ])
      pp <- droplevels(pp[pp$subjects %in% subject, ])
    }
    if (subject == "none"){
      dat <- data
      fnams <- names(dat)[!(names(dat) %in% c("subjects", "trials", "R", 
                                              "rt"))]
    }
    else if (!all(subject %in% snams)) 
      stop("Subject(s) not present\n")
    if (length(subject) > 1)
      fnams <- names(dat)[!(names(dat) %in% c("trials", 
                                              "R", "rt"))]
    else fnams <- names(dat)[!(names(dat) %in% c("subjects", 
                                                 "trials", "R", "rt"))]
  } 
  else {
    dat <- data
    fnams <- names(dat)[!(names(dat) %in% c("trials", "R", 
                                            "rt"))]
  }
  if (!is.null(factors)) {
    if (!all(factors %in% fnams)) 
      stop("factors must name factors in data")
    fnams <- factors
  }
  if (!is.null(layout)) 
    if (mfcol) par(mfcol = layout)
  else par(mfrow = layout)
  if (all(is.na(data$rt))) {
    if (length(levels(data$R)) == 2 & is.null(stat)) 
      stop("No plots for binary responses, use an accuracy function in stat argument.")
    if (!is.null(stat)) {
      cells <- dat[, fnams, drop = FALSE]
      for (i in fnams) cells[, i] <- paste(i, cells[, i], 
                                           sep = "=")
      cells <- apply(cells, 1, paste, collapse = " ")
      pp_cells <- pp[, fnams, drop = FALSE]
      for (i in fnams) pp_cells[, i] <- paste(i, pp_cells[, 
                                                          i], sep = "=")
      pp_cells <- apply(pp_cells, 1, paste, collapse = " ")
      postn <- unique(pp$postn)
      ucells <- sort(unique(cells))
      tab <- matrix(nrow = length(ucells), ncol = 4, dimnames = list(ucells, 
                                                                     c("Observed", names(quantile(1:5, ci)))))
      for (i in ucells) {
        obs <- stat(dat[cells == i, ])
        ppi <- pp[pp_cells == i, ]
        pred <- sapply(postn, function(x) {
          stat(ppi[ppi$postn == x, ])
        })
        if (do_plot) {
          dens <- density(pred, adjust = adjust)
          if (!is.null(xlim)) 
            xlimi <- xlim
          else xlimi <- c(pmin(obs, min(dens$x)), pmax(obs, 
                                                       max(dens$x)))
          plot(dens, main = i, xlab = stat_name, xlim = xlimi)
          abline(v = obs)
        }
        tab[i, ] <- c(obs, quantile(pred, ci))
      }
      invisible(tab)
    }
    else {
      if (!any(fnams == signalFactor)) 
        stop("Data does not have a column specified in the signalFactor argument: ", 
             signalFactor)
      if (length(levels(data[[signalFactor]])) != 2) 
        stop("signalFactor must have exactly two levels for an ROC plot")
      if (zROC & is.null(qfun)) 
        stop("Must supply qfun for zROC")
      fnams <- fnams[fnams != signalFactor]
      cells <- dat[, fnams, drop = FALSE]
      for (i in fnams) cells[, i] <- paste(i, cells[, i], 
                                           sep = "=")
      cells <- apply(cells, 1, paste, collapse = " ")
      pp_cells <- pp[, fnams, drop = FALSE]
      for (i in fnams) pp_cells[, i] <- paste(i, pp_cells[, 
                                                          i], sep = "=")
      pp_cells <- apply(pp_cells, 1, paste, collapse = " ")
      postn <- unique(pp$postn)
      ucells <- sort(unique(cells))
      for (i in ucells) {
        dpts <- plot_roc(dat[cells == i, ], zROC = zROC, 
                         qfun = qfun, lim = lim, main = i, signalFactor = signalFactor)
        tab <- table(pp[pp_cells == i, ]$postn, pp[pp_cells == 
                                                     i, ]$R, pp[pp_cells == i, ][[signalFactor]])
        ctab <- apply(tab, 1, function(x) {
          list(1 - apply(t(x)/apply(x, 2, sum), 1, cumsum)[-dim(x)[1], 
          ])
        })
        if (!zROC) 
          lapply(ctab, function(x) {
            points(x[[1]][, 1], x[[1]][, 2], col = "grey", 
                   pch = 16, cex = rocfit_cex)
          })
        else ctab <- lapply(ctab, function(x) {
          x[[1]] <- qnorm(x[[1]])
          points(x[[1]][row.names(dpts), 1], x[[1]][row.names(dpts), 
                                                    2], col = "grey", pch = 16, cex = rocfit_cex)
        })
        points(dpts[, 1], dpts[, 2])
        lines(dpts[, 1], dpts[, 2])
      }
    }
  }
  else {
    cells <- dat[, fnams, drop = FALSE]
    for (i in fnams) cells[, i] <- paste(i, cells[, i], sep = "=")
    cells <- apply(cells, 1, paste, collapse = " ")
    pp_cells <- pp[, fnams, drop = FALSE]
    for (i in fnams) pp_cells[, i] <- paste(i, pp_cells[, 
                                                        i], sep = "=")
    pp_cells <- apply(pp_cells, 1, paste, collapse = " ")
    if (!is.null(stat)) {
      postn <- unique(pp$postn)
      ucells <- sort(unique(cells))
      tab <- matrix(nrow = length(ucells), ncol = 4, dimnames = list(ucells, 
                                                                     c("Observed", names(quantile(1:5, ci)))))
      for (i in ucells) {
        obs <- stat(dat[cells == i, ])
        ppi <- pp[pp_cells == i, ]
        pred <- sapply(postn, function(x) {
          stat(ppi[ppi$postn == x, ])
        })
        if (do_plot) {
          dens <- density(pred, adjust = adjust)
          if (!is.null(xlim)) 
            xlimi <- xlim
          else xlimi <- c(pmin(obs, min(dens$x)), pmax(obs, 
                                                       max(dens$x)))
          plot(dens, main = i, xlab = stat_name, xlim = xlimi)
          abline(v = obs)
        }
        tab[i, ] <- c(obs, quantile(pred, ci))
      }
      invisible(tab)
    }
    else {
      pok <- probs %in% q_points
      R <- levels(dat$R)
      if (is.null(ylim)) 
        ylim <- c(0, 1)
      if (is.null(xlim)) {
        xlim <- c(Inf, -Inf)
        for (i in sort(unique(cells))) {
          dati <- dat[cells == i, ]
          ppi <- pp[pp_cells == i, ]
          pR <- table(dati$R)/dim(dati)[1]
          pqs <- pq <- qs <- setNames(vector(mode = "list", 
                                             length = length(R)), R)
          for (j in R) if (length(dati$rt[dati$R == j]) >= 
                           length(q_points)) {
            qs[[j]] <- quantile(dati$rt[dati$R == j], 
                                probs = probs)
            pq[[j]] <- quantile(ppi$rt[ppi$R == j], probs = probs)
            pqs[[j]] <- tapply(ppi$rt[ppi$R == j], ppi$postn[ppi$R == 
                                                               j], quantile, probs = probs[pok])
          }
          else qs[[j]] <- pq[[j]] <- pqs[[j]] <- NA
          rx <- cbind(do.call(rbind, lapply(qs, function(x) {
            x[c(1, length(probs))]
          })), do.call(rbind, lapply(pq, function(x) {
            x[c(1, length(probs))]
          })))
          xlimi <- c(min(rx, na.rm = TRUE), max(rx, na.rm = TRUE))
          if (!any(is.na(xlimi))) {
            xlim[1] <- pmin(xlim[1], xlimi[1])
            xlim[2] <- pmax(xlim[2], xlimi[2])
          }
        }
      }
      for (i in sort(unique(cells))) {
        title <- ifelse(i==sort(unique(cells))[1], "Congruent",
                        "Incongruent")
        dati <- dat[cells == i, ]
        ppi <- pp[pp_cells == i, ]
        pR <- table(dati$R)/dim(dati)[1]
        pqs <- pq <- qs <- setNames(vector(mode = "list", 
                                           length = length(R)), R)
        ppR <- pR
        ppR[1:length(pR)] <- 0
        for (j in R) if (length(dati$rt[dati$R == j]) >= 
                         length(q_points)) {
          isj <- ppi$R == j
          qs[[j]] <- quantile(dati$rt[dati$R == j], probs = probs)
          pq[[j]] <- quantile(ppi$rt[isj], probs = probs)
          pqs[[j]] <- tapply(ppi$rt[isj], ppi$postn[isj], 
                             quantile, probs = probs[pok])
          ppR[j] <- mean(isj)
        }
        else qs[[j]] <- pq[[j]] <- pqs[[j]] <- NA
        if (!any(is.na(pq[[1]]))) {
          par(mar=c(3,4,2,0) + 0.1)
          plot(pq[[1]], probs * ppR[1], xlim = xlim, 
               ylim = ylim, main = title, xlab = "", type = "l", col = "#3182bd",
               lwd = fit_lwd, ylab = "", lty = 1, axes=FALSE)
          axis(1, padj = -0.8)
          axis(2, las=1, hadj = 0.8)
          title(xlab = "RT", line=1.5)
          title(line=2.5, ylab = "Cumulative probability")
          tmp = lapply(pqs[[1]], function(x) {
            points(x, probs[pok] * ppR[1], col = "#3182bd", 
                   pch = 16, cex = pqp_cex)
          })
          points(pq[[1]][pok], probs[pok] * ppR[1], cex = pqp_cex * 
                   3, pch = 16, col = "#3182bd")
          lines(qs[[1]], probs * pR[1], lwd = data_lwd, 
                lty = 1, col = "#c51b8a")
          points(qs[[1]][pok], probs[pok] * pR[1], cex = qp_cex, 
                 pch = 16, col = "#c51b8a")
          do_plot = FALSE
        }
        else do_plot = TRUE
        if (length(qs) > 1) {
          for (j in 2:length(qs)) if (!any(is.na(pq[[j]]))) {
            if (do_plot) {
              plot(pq[[j]], probs * ppR[j], xlim = xlim, 
                   ylim = ylim, main = title, xlab = "RT", type = "l", 
                   lwd = fit_lwd, ylab = "Cumulative probability", lty = j,
                   col = "#c51b8a")
              do_plot <- FALSE
            }
            else lines(pq[[j]], probs * ppR[j], lwd = fit_lwd, 
                       lty = j, col= "#3182bd")
            tmp = lapply(pqs[[j]], function(x) {
              points(x, probs[pok] * ppR[j], col = "#3182bd", 
                     pch = 16, cex = pqp_cex)
            })
            points(pq[[j]][pok], probs[pok] * ppR[j], 
                   cex = pqp_cex * 3, pch = 16, col = "#3182bd")
            lines(qs[[j]], probs * pR[j], lwd = data_lwd, 
                  lty = j, col = "#c51b8a")
            points(qs[[j]][pok], probs[pok] * pR[j], 
                   cex = qp_cex, pch = 16, col = "#c51b8a")
          }
        }
      }
    }
  }
}


# individual pp checks
individual_pp_check <- function(data, modelfit, npred = 500){
  
  J <- data %>% group_by(subject) %>% count() %>% pull(n) %>% max()
  I <- length(unique(data$subject))
  filler <- -9999
  idx <- round(seq(from = 1, to = 4000, length.out = npred),0)
  y_pred <- rstan::extract(modelfit, "Y_pred")$Y_pred[idx,,,]
  
  pp_dat2 <- matrix(aperm(y_pred, c(3,2,1,4)), ncol = 3) %>% 
    as.data.frame() %>% 
    rename("rt" = V1, "accuracy" = V2, "cond" = V3) %>% 
    mutate(pp = rep(1:npred, each = I*J),
           s = rep(rep(1:I, each = J), times = npred)) %>% 
    filter(rt != filler, accuracy != filler, cond != filler)
  
  
  pp_deciles <- pp_dat2 %>% 
    mutate(congruency = cond) %>% 
    group_by(s, congruency) %>% 
    summarize(q10 = quantile(rt, probs = 0.1),
              q20 = quantile(rt, probs = 0.2),
              q30 = quantile(rt, probs = 0.3),
              q40 = quantile(rt,  probs = 0.4),
              q50 = median(rt),
              q60 = quantile(rt,  probs = 0.6),
              q70= quantile(rt,  probs = 0.7),
              q80 = quantile(rt,  probs = 0.8),
              q90 = quantile(rt,  probs = 0.9)) %>% 
    pivot_longer(names_to = "decile", values_to = "rt", cols = q10:q90)
  
  pp_deciles_obs <- data %>% 
    mutate(congruency = ifelse(congruency == 1, -0.5, 0.5)) %>% 
    group_by(subject)  %>% 
    mutate(s = group_indices()) %>% 
    group_by(s, congruency) %>% 
    summarize(q10 = quantile(rt, probs = 0.1),
              q20 = quantile(rt, probs = 0.2),
              q30 = quantile(rt, probs = 0.3),
              q40 = quantile(rt,  probs = 0.4),
              q50 = median(rt),
              q60 = quantile(rt,  probs = 0.6),
              q70= quantile(rt,  probs = 0.7),
              q80 = quantile(rt,  probs = 0.8),
              q90 = quantile(rt,  probs = 0.9))%>% 
    pivot_longer(names_to = "decile", values_to = "rt_obs", cols = q10:q90)
  
  qq_lnr_c <- left_join(pp_deciles_obs, pp_deciles) %>% 
    filter(congruency == -0.5) %>% 
    ggplot(aes(rt_obs, rt, label = s)) +
    geom_point() +
    geom_abline(intercept =0 , slope = 1) +
    facet_wrap(~decile)+
    ggtitle("Congruent", subtitle = "Individual observed and predicted response times across quantiles")+
    labs(y = "Response Time (Predicted)", x = "Response Time (Observed)")+
    theme_bw()
  
  qq_lnr_ic <- left_join(pp_deciles_obs, pp_deciles) %>% 
    filter(congruency == 0.5) %>% 
    ggplot(aes(rt_obs, rt, label = s)) +
    geom_point() +
    geom_abline(intercept =0 , slope = 1) +
    facet_wrap(~decile) +
    ggtitle("Incongruent", subtitle = "Individual observed and predicted response times across quantiles") +
    labs(y = "Response Time (Predicted)", x = "Response Time (Observed)") +
    theme_bw()
  
  return(list(congruent = qq_lnr_c,
              incongruent = qq_lnr_ic))
}

```

```{r 'von-Bastian-LNR-fitting', eval = F}
vonbastian <- read.csv("cleaned_data/vonbastianetal_2016.csv")

trialsum_vonbastian <- vonbastian %>% 
  group_by(subject) %>% 
  count() %>% 
  pull(n)
 
I_vonbastian <- length(unique(vonbastian$subject))
 from_vonbastian <- numeric(I_vonbastian)
 for(i in 1:I_vonbastian){
  if(i == 1){
    from_vonbastian[i] = 1;
  } else {
    from_vonbastian[i] = cumsum(trialsum_vonbastian)[i-1] + 1;
  }
 }
 
 dat_vonbastian <- vonbastian %>% 
   select(rt,accuracy,congruency) %>%
   mutate(accuracy = ifelse(accuracy == 1, 1, 2),
          congruency = ifelse(congruency == 1, -0.5, 0.5)) %>% 
   as.matrix()

 
 start_values <- function(){list(psi_mu = runif(1, 0.1, 0.2),
                                psi_sigma = runif(1, 0.01, 0.05),
                                psi = rep(times = I_vonbastian, runif(1, 0.1, 0.2),
                                alpha_1_mu = exp(runif(1, -1,0.5)),
                                alpha_2 = exp(runif(1, -1, 0.5)),
                                alpha_1_sigma = -0.5,
                                theta_sigma = -0.5,
                                theta_mu = exp(runif(1, -1, 1)),
                                alpha_1 = exp(rep(times = I_vonbastian, runif(1, -2, 1))),
                                theta = rep(times = I_vonbastian, runif(1, -1, 1)),
                                sigma_1 = rep(times = I_vonbastian, runif(1, -0.5, 0)),
                                sigma_1_sigma = -0.5,
                                sigma_mu = -0.5)
                                )} 

 
data_vB <- list(N = nrow(vonbastian), I = I_vonbastian, K = 2, Y = dat_vonbastian, 
                J = max(trialsum_vonbastian), 
                trialsum = trialsum_vonbastian, idx_start = from_vonbastian) 
 
stan_lnr_vB <- rstan::stan("stan_models/lnr.stan", data = data_vB, init = start_values, 
                               iter = 3000, warmup = 2000, chains = 4, 
                               control = list(adapt_delta = 0.98, stepsize = 0.4))

lnr_extract_vB <- rstan::extract(stan_lnr_vB, pars = c("mu_c", "mu_ic", "sigma_1", "theta_sigma"))

trialnr_vB <- vonbastian %>% 
  filter( accuracy == 1) %>% # only correct trials as stroop effect is only on correct drift
  mutate(cond = ifelse(congruency == 1, "c", "inc")) %>% 
  group_by(subject, cond) %>% 
  count()

#save(lnr_extract_vB, trialnr_vB, file="output/LNR/lnr_samplesfor_ratio_vB.RData")


#saveRDS(stan_lnr_vB, "output/LNR/lnr_vonbastian.RDS")
# posterior predictive checks ------------------------------------------------------------

plot_overall_lnr_vB <- pp_check_overall_lnr(vonbastian, stan_lnr_vB, 500)
ggsave("output/LNR/pp_lnr_vonBastian.pdf", plot_overall_lnr_vB, width = 4.71, height = 2.52, dev = cairo_pdf)

pdf(file = "output/LNR/plot_cdf_pp_vonbastian.pdf", width = 7, height = 3.5)
par(mfrow=c(1,2))    
plot_cdf_pp(data = vonbastian, modelfit = stan_lnr_vB, subject = "none", factors = "CT", 
          layout = NULL, xlim = c(0,5))  
dev.off()


individual_pp_vB <- individual_pp_check(vonbastian, stan_lnr_vB)
ggsave("output/LNR/ind_lnr_c_vB.pdf",individual_pp_vB$congruent, height = 5.8, width = 5.2, dev = cairo_pdf)
ggsave("output/LNR/ind_lnr_ic_vB.pdf",individual_pp_vB$incongruent, height = 5.8, width = 5.2, dev = cairo_pdf)

```

```{r 'Rey-Mermet-LNR-fitting', eval = F}
reymermet <- read.csv("cleaned_data/reymermetetal_2018.csv")

trialsum_reymermet <- reymermet %>% 
  group_by(subject) %>% 
  count() %>% 
  pull(n)
 
I_reymermet <- length(unique(reymermet$subject))
 from_reymermet <- numeric(I_reymermet)
 for(i in 1:I_reymermet){
  if(i == 1){
    from_reymermet[i] = 1;
  } else {
    from_reymermet[i] = cumsum(trialsum_reymermet)[i-1] + 1;
  }
 }
 
 dat_reymermet <- reymermet %>% 
   select(rt,accuracy,congruency) %>%
   mutate(accuracy = ifelse(accuracy == 1, 1, 2),
          congruency = ifelse(congruency == 1, -0.5, 0.5)) %>% 
   as.matrix()

 
 start_values <- function(){list(psi_mu = runif(1, 0.1, 0.2),
                                psi_sigma = runif(1, 0.01, 0.05),
                                psi = rep(times = I_reymermet, runif(1, 0.1, 0.2),
                                alpha_1_mu = exp(runif(1, -1,0.5)),
                                alpha_2 = exp(runif(1, -1, 0.5)),
                                alpha_1_sigma = exp(runif(1, -1, 0.5)),
                                theta_sigma = exp(runif(1, -1, 0.5)),
                                theta_mu = exp(runif(1, -1, 1)),
                                alpha_1 = exp(rep(times = I_reymermet, runif(1, -2, 1))),
                                theta = rep(times = I_reymermet, runif(1, -1, 1)),
                                sigma_1 = rep(times = I_reymermet, runif(1, -0.5, 0)),
                                sigma_1_sigma = exp(runif(1, -1, 0.5)),
                                sigma_mu = exp(runif(1, -1, 0.5)))
                                )} 

 
data_RMy <- list(N = nrow(reymermet), I = I_reymermet, K = 2, Y = dat_reymermet, 
                J = max(trialsum_reymermet), 
                trialsum = trialsum_reymermet, idx_start = from_reymermet) 
 
stan_lnr_RMy <- rstan::stan("stan_models/lnr.stan", data = data_RMy, init = start_values, 
                               iter = 3000, warmup = 2000, chains = 4, 
                               control = list(adapt_delta = 0.98, stepsize = 0.4))

lnr_extract_RMy <- rstan::extract(stan_lnr_RMy, pars = c("mu_c", "mu_ic", "sigma_1", "theta_sigma"))

trialnr_RMy <- reymermet %>% 
  filter( accuracy == 1) %>% # only correct trials as stroop effect is only on correct drift
  mutate(cond = ifelse(congruency == 1, "c", "inc")) %>% 
  group_by(subject, cond) %>% 
  count()

#save(lnr_extract_RMy, trialnr_RMy, file="output/LNR/lnr_samplesfor_ratio_RMy.RData")

#saveRDS(stan_lnr_RMy, "output/LNR/lnr_reymermet.RDS")

# posterior predictive checks ------------------------------------------------------------

plot_overall_lnr_RMy <- pp_check_overall_lnr(reymermet, stan_lnr_RMy, 500)
ggsave("output/LNR/pp_lnr_ReyMermet.pdf", plot_overall_lnr_RMy, width = 4.71, height = 2.52, dev = cairo_pdf)

pdf(file = "output/LNR/plot_cdf_pp_ReyMermet.pdf", width = 7, height = 3.5)
par(mfrow=c(1,2))    
plot_cdf_pp(data = reymermet, modelfit = stan_lnr_RMy, subject = "none", factors = "CT", 
          layout = NULL, xlim = c(0,5))  
dev.off()

individual_pp_RMy <- individual_pp_check(reymermet, stan_lnr_RMy)
ggsave("output/LNR/ind_lnr_c_RMy.pdf",individual_pp_RMy$congruent, height = 5.8, width = 5.2, dev = cairo_pdf)
ggsave("output/LNR/ind_lnr_ic_RMy.pdf",individual_pp_RMy$incongruent, height = 5.8, width = 5.2, dev = cairo_pdf)
```

```{r 'Pratte-LNR-fitting', eval = F}
pratte <- read.csv("cleaned_data/pratteetal_2010.csv")

trialsum_pratte <- pratte %>% 
  group_by(subject) %>% 
  count() %>% 
  pull(n)
 
I_pratte <- length(unique(pratte$subject))
 from_pratte <- numeric(I_pratte)
 for(i in 1:I_pratte){
  if(i == 1){
    from_pratte[i] = 1;
  } else {
    from_pratte[i] = cumsum(trialsum_pratte)[i-1] + 1;
  }
 }
 
 dat_pratte <- pratte %>% 
   select(rt,accuracy,congruency) %>%
   mutate(accuracy = ifelse(accuracy == 1, 1, 2),
          congruency = ifelse(congruency == 1, -0.5, 0.5)) %>% 
   as.matrix()

 
 start_values <- function(){list(psi_mu = runif(1, 0.1, 0.2),
                                psi_sigma = runif(1, 0.01, 0.05),
                                psi = rep(times = I_pratte, runif(1, 0.1, 0.2),
                                alpha_1_mu = exp(runif(1, -1,0.5)),
                                alpha_2 = exp(runif(1, -1, 0.5)),
                                alpha_1_sigma = exp(runif(1, -1, 0.5)),
                                theta_sigma = exp(runif(1, -1, 0.5)),
                                theta_mu = exp(runif(1, -1, 1)),
                                alpha_1 = exp(rep(times = I_pratte, runif(1, -2, 1))),
                                theta = rep(times = I_pratte, runif(1, -1, 1)),
                                sigma_1 = rep(times = I_pratte, runif(1, -0.5, 0)),
                                sigma_1_sigma = exp(runif(1, -1, 0.5)),
                                sigma_mu = exp(runif(1, -1, 0.5)))
                                )} 

 
data_P <- list(N = nrow(pratte), I = I_pratte, K = 2, Y = dat_pratte, 
                J = max(trialsum_pratte), 
                trialsum = trialsum_pratte, idx_start = from_pratte) 
 
stan_lnr_P <- rstan::stan("stan_models/lnr.stan", data = data_P, init = start_values, 
                               iter = 3000, warmup = 2000, chains = 4, 
                               control = list(adapt_delta = 0.98, stepsize = 0.4))

# extract estimates
lnr_extract_P <- rstan::extract(stan_lnr_P, pars = c("mu_c", "mu_ic", "sigma_1", "theta_sigma"))

trialnr_P <- pratte %>% 
  filter( accuracy == 1) %>% # only correct trials as stroop effect is only on correct drift
  mutate(cond = ifelse(congruency == 1, "c", "inc")) %>% 
  group_by(subject, cond) %>% 
  count()

#save(lnr_extract_P, trialnr_P, file="output/LNR/lnr_samplesfor_ratio_P.RData")

#saveRDS(stan_lnr_P, "output/LNR/lnr_pratte.RDS")

## pp checks--------------------------------------------------------------------
# proportion correct
mean(y_pred[,,,2][y_pred[,,,2]!=filler] == 1)
mean(pratte$accuracy==1)



plot_overall_lnr_P <- pp_check_overall_lnr(pratte, stan_lnr_P, 500)
ggsave("output/LNR/pp_lnr_Pratte.pdf", plot_overall_lnr_P, width = 4.71, height = 2.52, dev = cairo_pdf)

pdf(file = "output/LNR/plot_cdf_pp_pratte.pdf", width = 7, height = 3.5)
par(mfrow=c(1,2))    
plot_cdf_pp(data = pratte, modelfit = stan_lnr_P, subject = "none", factors = "CT", 
          layout = NULL, xlim = c(0,5))  
dev.off()


individual_pp_P <- individual_pp_check(pratte, stan_lnr_P)
ggsave("output/LNR/ind_lnr_c_P.pdf",individual_pp_P$congruent, height = 5.8, width = 5.2, dev = cairo_pdf)
ggsave("output/LNR/ind_lnr_ic_P.pdf",individual_pp_P$incongruent, height = 5.8, width = 5.2, dev = cairo_pdf)

```

```{r 'Enkavi-LNR-fitting', eval = F}
enkavi <- read.csv("cleaned_data/enkavietal_2019.csv")

trialsum_enkavi <- enkavi %>% 
  group_by(subject) %>% 
  count() %>% 
  pull(n)
 
I_enkavi <- length(unique(enkavi$subject))
 from_enkavi <- numeric(I_enkavi)
 for(i in 1:I_enkavi){
  if(i == 1){
    from_enkavi[i] = 1;
  } else {
    from_enkavi[i] = cumsum(trialsum_enkavi)[i-1] + 1;
  }
 }
 
 dat_enkavi <- enkavi %>% 
   select(rt,accuracy,congruency) %>%
   mutate(accuracy = ifelse(accuracy == 1, 1, 2),
          congruency = ifelse(congruency == 1, -0.5, 0.5)) %>% 
   as.matrix()

 
 start_values <- function(){list(psi_mu = runif(1, 0.1, 0.2),
                                psi_sigma = runif(1, 0.01, 0.05),
                                psi = rep(times = I_enkavi, runif(1, 0.1, 0.2),
                                alpha_1_mu = exp(runif(1, -1,0.5)),
                                alpha_2 = exp(runif(1, -1, 0.5)),
                                alpha_1_sigma = exp(runif(1, -1, 0.5)),
                                theta_sigma = exp(runif(1, -1, 0.5)),
                                theta_mu = exp(runif(1, -1, 1)),
                                alpha_1 = exp(rep(times = I_enkavi, runif(1, -2, 1))),
                                theta = rep(times = I_enkavi, runif(1, -1, 1)),
                                sigma_1 = rep(times = I_enkavi, runif(1, -0.5, 0)),
                                sigma_1_sigma = exp(runif(1, -1, 0.5)),
                                sigma_mu = exp(runif(1, -1, 0.5)))
                                )} 

 
data_E <- list(N = nrow(enkavi), I = I_enkavi, K = 2, Y = dat_enkavi, 
                J = max(trialsum_enkavi), 
                trialsum = trialsum_enkavi, idx_start = from_enkavi) 
 
stan_lnr_E <- rstan::stan("stan_models/lnr.stan", data = data_E, init = start_values, 
                               iter = 3000, warmup = 2000, chains = 4, 
                               control = list(adapt_delta = 0.98, stepsize = 0.4))

# extract estimates
lnr_extract_E <- rstan::extract(stan_lnr_E, pars = c("mu_c", "mu_ic", "sigma_1", "theta_sigma"))

trialnr_E <- enkavi %>% 
  filter( accuracy == 1) %>% # only correct trials as stroop effect is only on correct drift
  mutate(cond = ifelse(congruency == 1, "c", "inc")) %>% 
  group_by(subject, cond) %>% 
  count()

#save(lnr_extract_E, trialnr_E, file="output/LNR/lnr_samplesfor_ratio_E.RData")

#saveRDS(stan_lnr_E, "output/LNR/lnr_enkavi.RDS")

# posterior predictive checks ------------------------------------------------------------


plot_overall_lnr_E <- pp_check_overall_lnr(enkavi, stan_lnr_E, 500)
ggsave("output/LNR/pp_lnr_Enkavi.pdf", plot_overall_lnr_E, width = 4.71, height = 2.52, dev = cairo_pdf)

pdf(file = "output/LNR/plot_cdf_pp_enkavi.pdf", width = 7, height = 3.5)
par(mfrow=c(1,2))    
plot_cdf_pp(data = enkavi, modelfit = stan_lnr_E, subject = "none", factors = "CT", 
          layout = NULL, xlim = c(0,5))  
dev.off()

individual_pp_E <- individual_pp_check(enkavi, stan_lnr_E)
ggsave("output/LNR/ind_lnr_c_E.pdf",individual_pp_E$congruent, height = 5.8, width = 5.2, dev = cairo_pdf)
ggsave("output/LNR/ind_lnr_ic_E.pdf",individual_pp_E$incongruent, height = 5.8, width = 5.2, dev = cairo_pdf)
```


```{r 'SN-ratios-LNR-analytical', eval = F}
# Functions --------------------------------------------------------------------

sn_lnr_analytical <- function(extracted_samples){
  sigma_theta <- extracted_samples$theta_sigma
  sigma <- sqrt(rowMeans(extracted_samples$sigma_1^2))
  ratio_a <- sigma_theta/sigma
  return(list(ratio_a = ratio_a,
              sigma_theta = sigma_theta,
              sigma = sigma))
}

# Von Bastian et al.------------------------------------------------------------
load("output/LNR/lnr_samplesfor_ratio_vB.RData") # load previously saved samples

res_lnr_vB_a <- sn_lnr_analytical(lnr_extract_vB)

#saveRDS(res_lnr_vB_a, "output/LNR/ratio_lnr_vB_a.RDS")

# Pratte et al. ----------------------------------------------------------------

load("output/LNR/lnr_samplesfor_ratio_P.RData") # load previously saved samples

res_lnr_P_a <- sn_lnr_analytical(lnr_extract_P)

#saveRDS(res_lnr_P_a, "output/LNR/ratio_lnr_P_a.RDS")

# Rey-Mermet et al. ----------------------------------------------------------------

load("output/LNR/lnr_samplesfor_ratio_RMy.RData") # load previously saved samples

res_lnr_RMy_a <- sn_lnr_analytical(lnr_extract_RMy)

#saveRDS(res_lnr_RMy_a, "output/LNR/ratio_lnr_RMy_a.RDS")

# Enkavi et al. ----------------------------------------------------------------

load("output/LNR/lnr_samplesfor_ratio_E.RData") # load previously saved samples

res_lnr_E_a <- sn_lnr_analytical(lnr_extract_E)

#saveRDS(res_lnr_E_a, "output/LNR/ratio_lnr_E_a.RDS")
```



```{r 'SN-ratios-LNR-sim', eval = F}
# Functions --------------------------------------------------------------------

var_dmu <- function(ss,dtc,dti) {
  mc <- apply(dtc,2,mean)
  mi <- apply(dti,2,mean)
  var(mi-mc)
}  

getv <- function(s,i,samps,li, lc, r) { # for parallelization
  var_dmu(dtc=matrix(log(rlnorm(lc[i]*r,samps$mu_c[s, i], samps$sigma_1[s, i])),nrow=lc[i],ncol=r),
          dti=matrix(log(rlnorm(li[i]*r,samps$mu_ic[s, i], samps$sigma_1[s, i])),nrow=li[i],ncol=r))
}

# Von Bastian et al.------------------------------------------------------------
load("output/LNR/lnr_samplesfor_ratio_vB.RData") # load previously saved samples

I <- ncol(lnr_extract_vB$mu_c) # nr of participants
S <- 500# Nr of samples from posterior distributions
niter <- nrow(lnr_extract_vB$mu_c)
idx <- seq(1, niter, by = niter/S)
r=10000 # nr of replicates 

li <- trialnr_vB[trialnr_vB$cond=="inc",]$n # individual trial numbers per condition
lc <- trialnr_vB[trialnr_vB$cond=="c",]$n
ratio <- numeric(S)
effect_var_mean <- numeric(S)
sigma_theta <- numeric(S)
mean_L <- mean(trialnr_vB$n)

for(s in 1:S){
  idx_thin <- idx[s]
  effect_var <- unlist(mclapply(1:I,getv,s=idx_thin, li=li, lc=lc, r=r,samps=lnr_extract_vB,mc.cores=16))
  sigma_theta[s] <- lnr_extract_vB$theta_sigma[idx_thin]
  effect_var_mean[s] <- mean(effect_var)
  ratio[s] <- (sigma_theta[s]^2/((effect_var_mean[s]*mean_L)/2)) # average effect variance and trial number across individuals
  print(s)
}

#saveRDS(ratio, "output/ratio_lnr_vB.RDS")
#save(effect_var_mean, sigma_theta, ratio, file = "output/LNR/ratio_and_components_lnr_vB.RData")


# Pratte et al. ----------------------------------------------------------------

load("output/LNR/lnr_samplesfor_ratio_P.RData")

I <- ncol(lnr_extract_P$mu_c) # nr of participants
S <- 500# Nr of samples from posterior distributions
niter <- nrow(lnr_extract_P$mu_c)
idx <- seq(1, niter, by = niter/S)
r=10000 # nr of replicates 

li <- trialnr_P[trialnr_P$cond=="inc",]$n 
lc <- trialnr_P[trialnr_P$cond=="c",]$n
ratio <- numeric(S)
effect_var_mean <- numeric(S)
sigma_theta <- numeric(S)
mean_L <- mean(trialnr_P$n)

for(s in 1:S){
  idx_thin <- idx[s]
  effect_var <- unlist(mclapply(1:I,getv,s=idx_thin, li=li, lc=lc, r=r,samps=lnr_extract_P,mc.cores=16))
  sigma_theta[s] <- lnr_extract_P$theta_sigma[idx_thin]
  effect_var_mean[s] <- mean(effect_var)
  ratio[s] <- (sigma_theta[s]^2/((effect_var_mean[s]*mean_L)/2)) # average effect variance and trial number across individuals
  print(s)
}

#saveRDS(ratio, "output/LNR/ratio_lnr_P.RDS")
#save(effect_var_mean, sigma_theta, ratio, file = "output/LNR/ratio_and_components_lnr_P.RData")


# Rey-Mermet et al. ----------------------------------------------------------------

load("output/LNR/lnr_samplesfor_ratio_RMy.RData")

I <- ncol(lnr_extract_RMy$mu_c) # nr of participants
S <- 500# Nr of samples from posterior distributions
niter <- nrow(lnr_extract_RMy$mu_c)
idx <- seq(1, niter, by = niter/S)
r=10000 # nr of replicates 

li <- trialnr_RMy[trialnr_RMy$cond=="inc",]$n 
lc <- trialnr_RMy[trialnr_RMy$cond=="c",]$n
ratio <- numeric(S)
effect_var_mean <- numeric(S)
sigma_theta <- numeric(S)
mean_L <- mean(trialnr_RMy$n)

for(s in 1:S){
  idx_thin <- idx[s]
  effect_var <- unlist(mclapply(1:I,getv,s=idx_thin, li=li, lc=lc, r=r,samps=lnr_extract_RMy,mc.cores=16))
  sigma_theta[s] <- lnr_extract_RMy$theta_sigma[idx_thin]
  effect_var_mean[s] <- mean(effect_var)
  ratio[s] <- (sigma_theta[s]^2/((effect_var_mean[s]*mean_L)/2)) # average effect variance and trial number across individuals
  print(s)
}

#saveRDS(ratio, "output/LNR/ratio_lnr_RMy.RDS")
#save(effect_var_mean, sigma_theta, ratio, file = "output/LNR/ratio_and_components_lnr_RMy.RData")


# Enkavi et al. ----------------------------------------------------------------

load("output/LNR/lnr_samplesfor_ratio_E.RData")

I <- ncol(lnr_extract_E$mu_c) # nr of participants
S <- 500# Nr of samples from posterior distributions
niter <- nrow(lnr_extract_E$mu_c)
idx <- seq(1, niter, by = niter/S)
r=10000 # nr of replicates 

li <- trialnr_E[trialnr_E$cond=="inc",]$n 
lc <- trialnr_E[trialnr_E$cond=="c",]$n
ratio <- numeric(S)
effect_var_mean <- numeric(S)
sigma_theta <- numeric(S)
mean_L <- mean(trialnr_E$n)

for(s in 1:S){
  idx_thin <- idx[s]
  effect_var <- unlist(mclapply(1:I,getv,s=idx_thin, li=li, lc=lc, r=r,samps=lnr_extract_E,mc.cores=16))
  sigma_theta[s] <- lnr_extract_E$theta_sigma[idx_thin]
  effect_var_mean[s] <- mean(effect_var)
  ratio[s] <- (sigma_theta[s]^2/((effect_var_mean[s]*mean_L)/2)) # average effect variance and trial number across individuals
  print(s)
}

#saveRDS(ratio, "output/LNR/ratio_lnr_E.RDS")
#save(effect_var_mean, sigma_theta, ratio, file = "output/LNR/ratio_and_components_lnr_E.RData")

```


